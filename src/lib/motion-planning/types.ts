/**
 * Represents a single step within a larger motion plan.
 */
export interface MotionStep {
  /**
   * Identifies the type of camera motion for this step.
   * This MUST match a 'name' defined in the Motion Knowledge Base (KB).
   * Examples: "zoom", "orbit", "pan", "static", "fly_by"
   */
  type: string;

  /**
   * Contains the specific settings for this motion step.
   * The keys and expected value types depend on the 'type' of motion
   * and should align with the definitions in the Motion KB.
   * Examples:
   *   For "zoom": { "target": "object_center", "factor": 0.5, "speed": "fast" }
   *   For "orbit": { "direction": "clockwise", "axis": "y", "angle": 90, "speed": "medium" }
   *   For "static": {} (might have no parameters)
   */
  parameters: {
    [key: string]: string | number | boolean; // Allows string, number, or boolean values
  };

  /**
   * Specifies what proportion of the total animation duration
   * this step should take (value between 0.0 and 1.0).
   * The Scene Interpreter will calculate the actual duration based on this ratio
   * and the total requested_duration (if provided).
   * All ratios in the plan should ideally sum to 1.0.
   */
  duration_ratio: number;
}

/**
 * Represents the overall structured motion plan generated by an LLM Assistant/Agent
 * OR composed from a pattern.
 */
export interface MotionPlan {
  /**
   * An ordered list of motion steps to be executed sequentially.
   */
  steps: MotionStep[];

  /**
   * Optional: Extra information about the overall plan.
   */
  metadata?: {
    /**
     * The total duration (in seconds) the user originally requested or inferred.
     * Helps the Scene Interpreter scale the duration_ratios correctly.
     * If not provided, the interpreter might use a default duration or sum step durations differently.
     */
    requested_duration?: number;

    /**
     * Optional: The original user prompt, potentially useful for debugging.
     */
    original_prompt?: string;

    source?: 'assistant' | 'composer'; // Indicate if plan came directly from LLM or composer
    pattern?: string; // If source is 'composer', indicates which pattern was used

    // Add other metadata as needed
  };
}

/**
 * The possible responses from the MotionPlannerService.generatePlan method.
 */
export type AdapterPlanResponse =
  | { type: 'function_call'; name: string; arguments: string } // Arguments is JSON string
  | { type: 'motion_plan'; plan: MotionPlan };

/**
 * Interface for a service responsible for generating a structured MotionPlan
 * OR identifying a required function call from a user prompt.
 */
export interface MotionPlannerService {
  /**
   * Generates a structured motion plan or identifies a required function call.
   * @param userPrompt The natural language prompt from the user.
   * @param requestedDuration Optional total duration hint in seconds.
   * @returns A Promise resolving to an AdapterPlanResponse (either motion plan or function call).
   * @throws Error if the process fails.
   */
  generatePlan(userPrompt: string, requestedDuration?: number): Promise<AdapterPlanResponse>;

  /**
   * Optional: Validates the configuration and connectivity with the underlying AI provider.
   * @returns A Promise resolving to true if the configuration is valid, false otherwise.
   */
  validateConfiguration?(): Promise<boolean>;

  /**
   * Optional: Gets capabilities or information about the underlying provider.
   */
  getCapabilities?(): Promise<Record<string, any>>; // Define a more specific type if needed

  // Add other methods as needed (e.g., managing specific provider resources like threads)
}

/**
 * Defines the types of motion planning providers we might support.
 */
export type MotionProviderType = 'openai-assistant' | 'vertex-ai-agent' | 'mock'; // Add others as needed

/**
 * Base configuration expected for any motion planning provider adapter.
 */
export interface BaseMotionProviderConfig {
    type: MotionProviderType;
    // Add common config properties here (e.g., default timeout)
}

/**
 * Configuration specific to the OpenAI Assistant provider.
 */
export interface OpenAIAssistantProviderConfig extends BaseMotionProviderConfig {
    type: 'openai-assistant';
    apiKey: string;
    assistantId: string;
    // Optional: Specify KB file IDs if not automatically handled by the assistant's retrieval tool
    // knowledgeBaseFileIds?: string[];
    pollingIntervalMs?: number; // How often to check run status
    timeoutMs?: number; // Max time to wait for a run to complete
}

// Add configurations for other providers (VertexAI, Mock) as needed. 